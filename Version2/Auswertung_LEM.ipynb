{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea02c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inserted_markdown_preprocessor_def",
   "metadata": {},
   "source": [
    "### Manuelle Definition des Preprocessors und Mappings\n",
    "Die folgenden Werte müssen aus dem Trainingsprozess generiert und hier eingefügt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inserted_definitions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BEGINN DER WERTE, DIE AUS DEM TRAININGSSKRIPT GENERIERT WERDEN ===\n",
    "# Diese Werte müssen Sie mit den tatsächlichen Ausgaben Ihres Trainingsskripts ersetzen!\n",
    "label_to_score_map_notebook = {\n",
    "    0: (3, 0),\n",
    "    1: (3, 1),\n",
    "    2: (3, 2),\n",
    "    3: (0, 3),\n",
    "    4: (1, 3),\n",
    "    5: (2, 3),\n",
    "}\n",
    "N_CLASSES_NOTEBOOK = len(label_to_score_map_notebook)\n",
    "\n",
    "numerical_features_notebook = ['P1_Rank', 'P1_Pts', 'P2_Rank', 'P2_Pts', 'Best_of']\n",
    "categorical_features_notebook = ['Surface']\n",
    "\n",
    "# MinMaxScaler Parameter (BEISPIELWERTE - ERSETZEN!)\n",
    "min_scaler_min_ = np.array([  1.   ,  45.   ,   1.   ,  45.   ,   5.   ])\n",
    "min_scaler_scale_ = np.array([1.48882265e-03, 9.08265195e-05, 1.48882265e-03, 9.08265195e-05, 1.00000000e+00]) \n",
    "\n",
    "# OneHotEncoder Parameter (BEISPIELWERTE - ERSETZEN!)\n",
    "onehot_categories_ = [\n",
    "    np.array(['Clay', 'Hard', 'Grass'], dtype=object) # Reihenfolge und Inhalt aus Training!\n",
    "]\n",
    "input_shape_model_notebook = (8,) # BEISPIEL: 5 numerisch + 3 one-hot (Clay, Hard, Grass). Anpassen!\n",
    "# === ENDE DER WERTE, DIE AUS DEM TRAININGSSKRIPT GENERIERT WERDEN ===\n",
    "\n",
    "# Preprocessor manuell erstellen und konfigurieren\n",
    "manual_scaler = MinMaxScaler()\n",
    "manual_scaler.min_ = min_scaler_min_\n",
    "manual_scaler.scale_ = min_scaler_scale_\n",
    "manual_scaler.n_features_in_ = len(numerical_features_notebook)\n",
    "\n",
    "manual_onehot = OneHotEncoder(categories=onehot_categories_, handle_unknown='ignore', sparse_output=False)\n",
    "dummy_categorical_data = {col: [onehot_categories_[i][0]] for i, col in enumerate(categorical_features_notebook)}\n",
    "dummy_df_for_onehot_fit = pd.DataFrame(dummy_categorical_data, columns=categorical_features_notebook)\n",
    "manual_onehot.fit(dummy_df_for_onehot_fit)\n",
    "\n",
    "preprocessor_notebook = ColumnTransformer([\n",
    "    ('numerical', manual_scaler, numerical_features_notebook),\n",
    "    ('categorical', manual_onehot, categorical_features_notebook)\n",
    "], remainder='passthrough')\n",
    "\n",
    "dummy_data_for_ct_fit = {col: [0] for col in numerical_features_notebook}\n",
    "for i, col in enumerate(categorical_features_notebook):\n",
    "    dummy_data_for_ct_fit[col] = [onehot_categories_[i][0]]\n",
    "column_order_for_df_ct_fit = numerical_features_notebook + categorical_features_notebook\n",
    "dummy_df_for_ct_fit = pd.DataFrame(dummy_data_for_ct_fit, columns=column_order_for_df_ct_fit)\n",
    "preprocessor_notebook.fit(dummy_df_for_ct_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a7d874",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_path = \"tennis_set_predictor_final.keras\" \n",
    "loaded_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f042e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sets(X_processed_for_model, p1_rank_raw, p2_rank_raw):\n",
    "    \"\"\"Erwartet bereits prozessierte Daten für das Modell und die rohen Ränge für Fallback.\"\"\"\n",
    "    y_pred_proba = loaded_model.predict(X_processed_for_model)\n",
    "    predicted_label = np.argmax(y_pred_proba, axis=1)[0]\n",
    "    predicted_score = label_to_score_map_notebook[predicted_label]\n",
    "\n",
    "    # Konsistenzprüfung für Best-of-5 (da X immer Best of 5 sein wird für die Challenge)\n",
    "    s1, s2 = predicted_score\n",
    "    # Gewinner muss 3 Sätze haben, Verlierer weniger als 3. Gesamtzahl Sätze zwischen 3 und 5.\n",
    "    is_valid_bo5 = ((s1 == 3 and 0 <= s2 < 3) or (s2 == 3 and 0 <= s1 < 3)) and (3 <= s1 + s2 <= 5)\n",
    "\n",
    "    if is_valid_bo5:\n",
    "        return list(predicted_score)\n",
    "    else:\n",
    "        # Fallback-Logik: Wenn die Vorhersage ungültig ist,\n",
    "        # gib eine plausible Standardvorhersage zurück (z.B. Spieler mit besserem Rang gewinnt 3:0 oder 3:1).\n",
    "        # Dies ist eine sehr einfache Heuristik.\n",
    "        print(f\"WARNUNG: Ungültige Vorhersage {predicted_score}. Fallback wird verwendet.\")\n",
    "        if p1_rank_raw < p2_rank_raw: # Spieler 1 hat besseres Ranking (niedriger ist besser)\n",
    "            return [3, 0] \n",
    "        elif p2_rank_raw < p1_rank_raw: # Spieler 2 hat besseres Ranking\n",
    "            return [0, 3]\n",
    "        else: # Ränge gleich, oder einer ist NaN - sicherer Fallback\n",
    "            return [3, 0] # Oder eine andere zufällige plausible Wahl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb5fddb",
   "metadata": {},
   "source": [
    "# NICHT DIE STRUKTUR VERÄNDERN\n",
    "In der folgenden Zelle muss die Struktur exakt so erhalten bleiben, wie sie im Kommentar aufgelistet ist. Es dürfen lediglich die Werte ersetzt werden, aber es müssen immer alle Werte in exakt dieser Reihenfolge angegeben werden. Sollten Sie die Werte noch bearbeiten müssen, tun Sie dies bitte in der Zelle darunter. Es dürfen keine weiteren Werte wie Betting Rates in die Evaluation einfließen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb842309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATP, Location, Tournament, Date, Series, Court, Surface, Round, Best of, Winner, Loser, WRank, LRank, WPts, LPts\n",
    "X = [1, \"Paris\", \"Roland Garros\", \"26.05.2024\", \"Grand Slam\", \"Outdoor\", \"Clay\", \"Quarterfinals\", 5, \"Alcaraz C.\", \"Djokovic N.\", 2, 1, 8900, 11200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a45ee03",
   "metadata": {
    "tags": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc0d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X_single_match_raw_list):\n",
    "    \"\"\"\n",
    "    Bereitet die Rohdaten für EIN Match für die Modellvorhersage vor.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        p1_rank_raw = X_single_match_raw_list[11]\n",
    "        p2_rank_raw = X_single_match_raw_list[12]\n",
    "\n",
    "        p1_rank = float(p1_rank_raw) if p1_rank_raw is not None else np.nan\n",
    "        p2_rank = float(p2_rank_raw) if p2_rank_raw is not None else np.nan \n",
    "        p1_pts = float(X_single_match_raw_list[13]) if X_single_match_raw_list[13] is not None else np.nan\n",
    "        p2_pts = float(X_single_match_raw_list[14]) if X_single_match_raw_list[14] is not None else np.nan\n",
    "        surface = X_single_match_raw_list[6]\n",
    "        best_of = float(X_single_match_raw_list[8])\n",
    "        \n",
    "        # Fallback für NaN Ranks/Points (z.B. mit einem Durchschnitt oder sehr schlechtem Wert)\n",
    "        # Hier verwenden wir einen hohen Rang und 0 Punkte als einfachen Fallback.\n",
    "        # Die Skalierung sollte damit umgehen können, solange die Trainingsdaten auch NaNs (oder imputierte Werte) hatten.\n",
    "        # Es ist wichtig, dass der Scaler mit der Möglichkeit von NaNs (oder den Imputationswerten) trainiert wurde.\n",
    "        # Wenn der Scaler im Training nie NaNs gesehen hat, ist dies ein Problem.\n",
    "        # Eine einfache Imputation hier:\n",
    "        p1_rank = p1_rank if pd.notna(p1_rank) else 2000.0 # Hoher Rang als Fallback\n",
    "        p2_rank = p2_rank if pd.notna(p2_rank) else 2000.0\n",
    "        p1_pts = p1_pts if pd.notna(p1_pts) else 0.0\n",
    "        p2_pts = p2_pts if pd.notna(p2_pts) else 0.0\n",
    "\n",
    "        data_for_df = {\n",
    "            'P1_Rank': [p1_rank],\n",
    "            'P1_Pts': [p1_pts],\n",
    "            'P2_Rank': [p2_rank],\n",
    "            'P2_Pts': [p2_pts],\n",
    "            'Best_of': [best_of],\n",
    "            'Surface': [surface]\n",
    "        }\n",
    "        \n",
    "        column_order_for_df = numerical_features_notebook + categorical_features_notebook\n",
    "        X_df_eval = pd.DataFrame(data_for_df, columns=column_order_for_df)\n",
    "        \n",
    "        X_processed_eval = preprocessor_notebook.transform(X_df_eval)\n",
    "        \n",
    "        # Rückgabe der rohen Ränge für die Fallback-Logik in predict_sets\n",
    "        return X_processed_eval, p1_rank_raw, p2_rank_raw \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler in prepare_data für {X_single_match_raw_list}: {e}\")\n",
    "        # Die Variable input_shape_model_notebook sollte aus der Definitionszelle kommen\n",
    "        num_output_features = input_shape_model_notebook[0]\n",
    "        print(f\"Fehlerbehandlung: Erzeuge Nullvektor der Länge {num_output_features}\")\n",
    "        # Gebe auch Fallback-Ränge zurück, die zu einer Standardvorhersage führen\n",
    "        return np.zeros((1, num_output_features)), 1000.0, 1000.0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdbea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier wird ausgewertet.\n",
    "prepared_X_data, p1_rank_raw, p2_rank_raw = prepare_data(X) \n",
    "print(f\"Form von prepared_X_data: {prepared_X_data.shape}\") \n",
    "prediction_output = predict_sets(prepared_X_data, p1_rank_raw, p2_rank_raw)\n",
    "print(prediction_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}